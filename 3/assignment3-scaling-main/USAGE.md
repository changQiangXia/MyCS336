# CS336 Assignment 3: ä½¿ç”¨è¯´æ˜

## ğŸ“ ä»£ç ç»“æ„

```
cs336_scaling/
â”œâ”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ model.py                 # Transformer æ¨¡å‹ (å·²æœ‰)
â”œâ”€â”€ utils.py                 # å·¥å…·å‡½æ•° (å‚æ•°é‡è®¡ç®—ç­‰)
â”œâ”€â”€ chinchilla_isoflops.py   # é—®é¢˜1: ä½¿ç”¨å·²æœ‰æ•°æ®æ‹Ÿåˆ IsoFLOPs
â”œâ”€â”€ scaling_api.py           # API å°è£… + Mock API
â””â”€â”€ scaling_experiment.py    # é—®é¢˜2: ä¸»åŠ¨å®éªŒç­–ç•¥

tests/
â”œâ”€â”€ test_chinchilla.py       # é—®é¢˜1çš„æµ‹è¯•
â”œâ”€â”€ test_api.py              # APIæµ‹è¯•
â””â”€â”€ test_experiment.py       # é—®é¢˜2çš„æµ‹è¯•

run_analysis.py              # ä¸»è¿è¡Œè„šæœ¬
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. é…ç½®ç¯å¢ƒ

åœ¨ **Anaconda Prompt** ä¸­æ‰§è¡Œï¼š

```bash
cd d:\pythonProjects\CS336\3\assignment3-scaling-main
uv sync
uv add scipy matplotlib numpy
```

### 2. è¿è¡Œé—®é¢˜1ï¼ˆä½¿ç”¨å·²æœ‰æ•°æ®ï¼‰

```bash
uv run python run_analysis.py --problem 1
```

è¿™ä¼šï¼š
- åŠ è½½ `data/isoflops_curves.json` æ•°æ®
- å¯¹æ¯ä¸ªè®¡ç®—é¢„ç®—æ‰¾åˆ°æœ€ä¼˜æ¨¡å‹å¤§å°
- æ‹Ÿåˆå¹‚å¾‹: N_opt = a Ã— C^b
- é¢„æµ‹ 10Â²Â³ å’Œ 10Â²â´ FLOPs çš„æœ€ä¼˜é…ç½®
- ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ä¿å­˜åˆ° `results/` ç›®å½•

### 3. è¿è¡Œé—®é¢˜2ï¼ˆä½¿ç”¨ Mock APIï¼‰

```bash
uv run python run_analysis.py --problem 2 --mock
```

è¿™ä¼šï¼š
- ä½¿ç”¨æ¨¡æ‹Ÿ APIï¼ˆä¸éœ€è¦ VPNï¼‰
- åœ¨ 2e18 FLOPs é¢„ç®—å†…è®¾è®¡å®éªŒ
- æ‹Ÿåˆç¼©æ”¾å®šå¾‹
- é¢„æµ‹ 1e19 FLOPs çš„æœ€ä¼˜é…ç½®

### 4. è¿è¡Œæµ‹è¯•

```bash
uv run python run_analysis.py --test
```

æˆ–ç›´æ¥ä½¿ç”¨ pytestï¼š

```bash
uv run python -m pytest tests/ -v
```

---

## ğŸ§ª æµ‹è¯•è¯´æ˜

### æµ‹è¯•åˆ†ç±»

| æµ‹è¯•æ–‡ä»¶ | å†…å®¹ |
|---------|------|
| `test_chinchilla.py` | é—®é¢˜1çš„å•å…ƒæµ‹è¯• |
| `test_api.py` | API å’Œ Mock API æµ‹è¯• |
| `test_experiment.py` | é—®é¢˜2çš„å®éªŒæµç¨‹æµ‹è¯• |

### æµ‹è¯•è¦†ç›–

- **æ•°æ®åŠ è½½å’Œè§£æ**
- **å¹‚å¾‹æ‹Ÿåˆ** (log-space å’Œ non-linear)
- **æœ€ä¼˜é…ç½®æŸ¥æ‰¾**
- **API å‚æ•°éªŒè¯**
- **é¢„ç®—ç®¡ç†**
- **Mock API ä¸€è‡´æ€§**
- **å®Œæ•´å®éªŒæµç¨‹**

---

## ğŸ“Š ä»£ç ä½¿ç”¨ç¤ºä¾‹

### é—®é¢˜1: ç›´æ¥ä½¿ç”¨å·²æœ‰æ•°æ®

```python
from cs336_scaling.chinchilla_isoflops import run_chinchilla_analysis

# è¿è¡Œå®Œæ•´åˆ†æ
results = run_chinchilla_analysis(
    target_budgets=[1e23, 1e24],
    output_dir="results"
)

# æŸ¥çœ‹ç»“æœ
print(f"Model scaling: N = {results['model_scaling']['a']:.3e} * C^{results['model_scaling']['b']:.4f}")
```

### é—®é¢˜2: ä½¿ç”¨ Mock API

```python
from cs336_scaling.scaling_experiment import ScalingExperiment, chinchilla_style_strategy

# åˆ›å»ºå®éªŒ
experiment = ScalingExperiment(
    budget=2e18,
    target_compute=1e19,
    use_mock=True,  # ä½¿ç”¨æ¨¡æ‹Ÿ API
)

# è¿è¡Œç­–ç•¥
chinchilla_style_strategy(experiment, num_isoflops_profiles=4, models_per_profile=5)

# æ‹Ÿåˆç¼©æ”¾å®šå¾‹
experiment.fit_scaling_law()

# é¢„æµ‹æœ€ä¼˜é…ç½®
prediction = experiment.predict_optimal_config()
print(f"Predicted: d_model={prediction['d_model']}, layers={prediction['num_layers']}")
```

### è‡ªå®šä¹‰å®éªŒé…ç½®

```python
from cs336_scaling.scaling_api import ExperimentConfig

config = ExperimentConfig(
    d_model=256,           # [64, 1024]
    num_layers=4,          # [2, 24]
    num_heads=4,           # [2, 16]
    batch_size=128,        # {128, 256}
    learning_rate=0.001,   # [1e-4, 1e-3]
    train_flops=1e15,      # å¯é€‰å€¼è§ VALID_RANGES
)
```

---

## ğŸ”§ æ ¸å¿ƒå…¬å¼

### æ¨¡å‹å‚æ•°é‡
```
N = 12 Ã— num_layers Ã— d_modelÂ²
```

### æ•°æ®é›†å¤§å°
```
D = C / (6 Ã— N)
```

### ç¼©æ”¾å®šå¾‹
```
N_opt = a Ã— C^b
D_opt = c Ã— C^d
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

è¿è¡Œåä¼šç”Ÿæˆï¼š

```
results/
â”œâ”€â”€ model_size_scaling.png      # æ¨¡å‹å¤§å°ç¼©æ”¾å®šå¾‹å›¾
â”œâ”€â”€ dataset_size_scaling.png    # æ•°æ®é›†å¤§å°ç¼©æ”¾å®šå¾‹å›¾
â””â”€â”€ experiment_results.png      # å®éªŒç»“æœå›¾ (é—®é¢˜2)
```

---

## â“ å¸¸è§é—®é¢˜

### Q: æˆ‘æ²¡æœ‰ Stanford VPNï¼Œèƒ½åšä»€ä¹ˆï¼Ÿ
**A:** å¯ä»¥å®Œæˆé—®é¢˜1ï¼ˆä½¿ç”¨å·²æœ‰æ•°æ®ï¼‰ï¼Œä»¥åŠç”¨ Mock API è¿è¡Œé—®é¢˜2çš„å®Œæ•´æµç¨‹æ¥å­¦ä¹ æ–¹æ³•è®ºã€‚

### Q: Mock API çš„ç»“æœå’ŒçœŸå® API ä¸€æ ·å—ï¼Ÿ
**A:** Mock API ä½¿ç”¨åŸºäºæ–‡çŒ®çš„å¯å‘å¼å…¬å¼æ¨¡æ‹ŸæŸå¤±ï¼Œç”¨äºä»£ç è°ƒè¯•å’Œç­–ç•¥éªŒè¯ã€‚çœŸå®ç»“æœéœ€è¦è¿æ¥ Stanford çš„ APIã€‚

### Q: å¦‚ä½•éªŒè¯ä»£ç æ­£ç¡®æ€§ï¼Ÿ
**A:** è¿è¡Œ `uv run python run_analysis.py --test`ï¼Œæ‰€æœ‰æµ‹è¯•éƒ½åº”è¯¥é€šè¿‡ã€‚

### Q: å¯ä»¥ä¿®æ”¹å®éªŒç­–ç•¥å—ï¼Ÿ
**A:** å¯ä»¥ï¼åœ¨ `scaling_experiment.py` ä¸­å®ç°æ–°çš„ç­–ç•¥å‡½æ•°ï¼Œå‚è€ƒ `chinchilla_style_strategy` çš„å†™æ³•ã€‚

---

## ğŸ“š å‚è€ƒ

- Hoffmann et al. 2022 (Chinchilla): Training Compute-Optimal Large Language Models
- Kaplan et al. 2020: Scaling Laws for Neural Language Models
